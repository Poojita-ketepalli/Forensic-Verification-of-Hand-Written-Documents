{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: split_folders in d:\\anaconda\\lib\\site-packages (0.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install split_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 2746 files [00:49, 55.64 files/s]\n"
     ]
    }
   ],
   "source": [
    "input_folder = r\"E:\\ML\\IBM hackathon research-forensic\\data_subset\\Authors\"\n",
    "output = r\"E:\\ML\\IBM hackathon research-forensic\\data_subset\\Authors-processed_data\"\n",
    "splitfolders.ratio(input_folder, output, seed=42, ratio=(.6, .2, .2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D,Flatten,Dense,MaxPool2D,BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import Activation, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = (224,224)\n",
    "batch_size = 32\n",
    "\n",
    "train_data_dir = r\"E:\\ML\\IBM hackathon research-forensic\\data_subset\\Authors-processed_data\\train\"\n",
    "valid_data_dir = r\"E:\\ML\\IBM hackathon research-forensic\\data_subset\\Authors-processed_data\\val\"\n",
    "test_data_dir = r\"E:\\ML\\IBM hackathon research-forensic\\data_subset\\Authors-processed_data\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 1079)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# read image\n",
    "img = cv2.imread(r'E:\\ML\\IBM hackathon research-forensic\\data_subset\\Authors-processed_data\\val\\a02\\a02-020-s00-02.png', cv2.IMREAD_UNCHANGED)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "\n",
    "img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 990 images belonging to 12 classes.\n",
      "Found 213 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  validation_split=0.4)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size=(img_height, img_width),\n",
    "batch_size=batch_size,\n",
    "class_mode='categorical',\n",
    "subset='training') # set as training data\n",
    "\n",
    "valid_generator = train_datagen.flow_from_directory(\n",
    "valid_data_dir, # some directory as training data\n",
    "target_size=(img_height, img_width),\n",
    "batch_size=batch_size,\n",
    "class_mode='categorical',\n",
    "subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 217 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = train_datagen.flow_from_directory(\n",
    "test_data_dir, # some directory as training data\n",
    "target_size=(img_height, img_width),\n",
    "batch_size=1,\n",
    "class_mode='categorical',\n",
    "subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = test_generator.next()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape=x.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31/31 [==============================] - 117s 3s/step - loss: 2.9890 - accuracy: 0.2498\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 105s 3s/step - loss: 1.3157 - accuracy: 0.5520\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 108s 3s/step - loss: 0.9955 - accuracy: 0.6575\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 108s 3s/step - loss: 1.0415 - accuracy: 0.6170\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 108s 3s/step - loss: 0.7786 - accuracy: 0.7537\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 105s 3s/step - loss: 0.6945 - accuracy: 0.7596\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 105s 3s/step - loss: 0.6404 - accuracy: 0.7955\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 104s 3s/step - loss: 0.6286 - accuracy: 0.7725\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 106s 3s/step - loss: 0.5959 - accuracy: 0.8027\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 105s 3s/step - loss: 0.5498 - accuracy: 0.8105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18d20efaee0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = ResNet50(include_top=False, weights='imagenet')\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(train_generator,\n",
    "         epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/217 - 33s - loss: 1.1817 - accuracy: 0.6313\n",
      "\n",
      "Test accuracy: 0.6313363909721375\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 24s 3s/step - loss: 1.7289 - accuracy: 0.4836\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 24s 3s/step - loss: 1.3243 - accuracy: 0.5258\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.9833 - accuracy: 0.6667\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 23s 3s/step - loss: 0.8118 - accuracy: 0.7371\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.7382 - accuracy: 0.7746\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6366 - accuracy: 0.7934\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5053 - accuracy: 0.8498\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.4935 - accuracy: 0.8498\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5129 - accuracy: 0.8263\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.4682 - accuracy: 0.8404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18d1f5860d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(valid_generator, epochs=10, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "31/31 [==============================] - 117s 3s/step - loss: 2.9634 - accuracy: 0.2347\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 108s 3s/step - loss: 1.5343 - accuracy: 0.4804\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 104s 3s/step - loss: 1.2454 - accuracy: 0.5681\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 101s 3s/step - loss: 1.1810 - accuracy: 0.5698\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 107s 3s/step - loss: 1.0742 - accuracy: 0.6165\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 109s 3s/step - loss: 0.9488 - accuracy: 0.6749\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 108s 3s/step - loss: 0.8971 - accuracy: 0.6751\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 109s 3s/step - loss: 0.7639 - accuracy: 0.7532\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 107s 3s/step - loss: 0.7639 - accuracy: 0.7362\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 107s 3s/step - loss: 0.7178 - accuracy: 0.7464\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 106s 3s/step - loss: 0.8329 - accuracy: 0.6937\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 105s 3s/step - loss: 0.6776 - accuracy: 0.7535\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 113s 4s/step - loss: 0.6174 - accuracy: 0.7720\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 105s 3s/step - loss: 0.6445 - accuracy: 0.7740\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 105s 3s/step - loss: 0.6546 - accuracy: 0.7741\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 105s 3s/step - loss: 0.5028 - accuracy: 0.8212\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 106s 3s/step - loss: 0.5396 - accuracy: 0.8206\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 107s 3s/step - loss: 0.5655 - accuracy: 0.8069\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 113s 4s/step - loss: 0.5184 - accuracy: 0.7954\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 112s 4s/step - loss: 0.4796 - accuracy: 0.8321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18d20f24dc0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = ResNet50(include_top=False, weights='imagenet')\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(train_generator,\n",
    "         epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 22s 3s/step - loss: 2.2512 - accuracy: 0.4789\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 23s 3s/step - loss: 1.4278 - accuracy: 0.5023\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 23s 3s/step - loss: 1.1261 - accuracy: 0.6244\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 23s 3s/step - loss: 1.0565 - accuracy: 0.6150\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.9768 - accuracy: 0.6620\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.7873 - accuracy: 0.7042\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6981 - accuracy: 0.7512\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6477 - accuracy: 0.7700\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5981 - accuracy: 0.8075\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6840 - accuracy: 0.7793\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5939 - accuracy: 0.7653\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5268 - accuracy: 0.8216\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.4942 - accuracy: 0.8357\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.4275 - accuracy: 0.8451\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5224 - accuracy: 0.8216\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.4024 - accuracy: 0.8920\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.3931 - accuracy: 0.8592\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.4170 - accuracy: 0.8592\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 23s 3s/step - loss: 0.3385 - accuracy: 0.8732\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 23s 3s/step - loss: 0.3612 - accuracy: 0.8638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18d26c80040>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(valid_generator, epochs=20, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/217 - 27s - loss: 1.3107 - accuracy: 0.6590\n",
      "\n",
      "Test accuracy: 0.6589861512184143\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31/31 [==============================] - 89s 3s/step - loss: 2.8050 - accuracy: 0.1974\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 92s 3s/step - loss: 1.8919 - accuracy: 0.3171\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 96s 3s/step - loss: 1.5875 - accuracy: 0.4498\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 110s 4s/step - loss: 1.3869 - accuracy: 0.5399\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 103s 3s/step - loss: 1.3387 - accuracy: 0.5164\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 103s 3s/step - loss: 1.2239 - accuracy: 0.5223\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 107s 3s/step - loss: 1.0604 - accuracy: 0.6284\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 106s 3s/step - loss: 1.0790 - accuracy: 0.6241\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 109s 4s/step - loss: 1.0383 - accuracy: 0.6278\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 112s 4s/step - loss: 0.9339 - accuracy: 0.6689\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 141s 5s/step - loss: 0.9681 - accuracy: 0.6664\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 104s 3s/step - loss: 0.8929 - accuracy: 0.6732\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 102s 3s/step - loss: 0.8064 - accuracy: 0.7120\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 103s 3s/step - loss: 0.7745 - accuracy: 0.7262\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 102s 3s/step - loss: 0.8323 - accuracy: 0.6978\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 104s 3s/step - loss: 0.8036 - accuracy: 0.7179\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 104s 3s/step - loss: 0.7087 - accuracy: 0.7223\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 103s 3s/step - loss: 0.7485 - accuracy: 0.7369\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 101s 3s/step - loss: 0.7760 - accuracy: 0.7117\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 108s 3s/step - loss: 0.7142 - accuracy: 0.7582\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 102s 3s/step - loss: 0.6457 - accuracy: 0.7663\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 107s 3s/step - loss: 0.6814 - accuracy: 0.7420\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 101s 3s/step - loss: 0.6215 - accuracy: 0.7671\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 98s 3s/step - loss: 0.6576 - accuracy: 0.7711\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 101s 3s/step - loss: 0.6718 - accuracy: 0.7796\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 100s 3s/step - loss: 0.5505 - accuracy: 0.8090\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 102s 3s/step - loss: 0.6968 - accuracy: 0.7634\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 104s 3s/step - loss: 0.5314 - accuracy: 0.8139\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 101s 3s/step - loss: 0.5824 - accuracy: 0.7782\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 104s 3s/step - loss: 0.6050 - accuracy: 0.7639\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 107s 3s/step - loss: 0.5683 - accuracy: 0.7933\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 105s 3s/step - loss: 0.5492 - accuracy: 0.8058\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 105s 3s/step - loss: 0.5134 - accuracy: 0.8144\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 108s 3s/step - loss: 0.5805 - accuracy: 0.7974\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 106s 3s/step - loss: 0.5370 - accuracy: 0.8049\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 98s 3s/step - loss: 0.5898 - accuracy: 0.8199\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 98s 3s/step - loss: 0.5646 - accuracy: 0.8028\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 98s 3s/step - loss: 0.5720 - accuracy: 0.7995\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 99s 3s/step - loss: 0.4204 - accuracy: 0.8399\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 99s 3s/step - loss: 0.4722 - accuracy: 0.8287\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 99s 3s/step - loss: 0.5241 - accuracy: 0.8112\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 97s 3s/step - loss: 0.4968 - accuracy: 0.8097\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 97s 3s/step - loss: 0.5325 - accuracy: 0.8200\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 95s 3s/step - loss: 0.4924 - accuracy: 0.8215\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 94s 3s/step - loss: 0.4748 - accuracy: 0.8474\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 95s 3s/step - loss: 0.5024 - accuracy: 0.8263\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 95s 3s/step - loss: 0.3838 - accuracy: 0.8582\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 94s 3s/step - loss: 0.4739 - accuracy: 0.8475\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 491s 16s/step - loss: 0.4392 - accuracy: 0.8592\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 97s 3s/step - loss: 0.5308 - accuracy: 0.8099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18d3fd7ae80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = ResNet50(include_top=False, weights='imagenet')\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.50)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(train_generator, \n",
    "         epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7/7 [==============================] - 17s 3s/step - loss: 2.7188 - accuracy: 0.4507\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 18s 2s/step - loss: 1.7147 - accuracy: 0.4319\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 19s 3s/step - loss: 1.3893 - accuracy: 0.5023\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 1.2715 - accuracy: 0.5493\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 1.1665 - accuracy: 0.5962\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 1.0349 - accuracy: 0.6573\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.9591 - accuracy: 0.6009\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.9079 - accuracy: 0.6714\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.8699 - accuracy: 0.7183\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.8054 - accuracy: 0.7136\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.7917 - accuracy: 0.6995\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.6507 - accuracy: 0.7277\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.5731 - accuracy: 0.7981\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.6368 - accuracy: 0.7700\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.5524 - accuracy: 0.7840\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.6202 - accuracy: 0.7700\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.6910 - accuracy: 0.7793\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.5005 - accuracy: 0.8263\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.5892 - accuracy: 0.7746\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.6263 - accuracy: 0.7606\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 23s 3s/step - loss: 0.6111 - accuracy: 0.7793\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 23s 3s/step - loss: 0.4460 - accuracy: 0.8451\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 24s 4s/step - loss: 0.5685 - accuracy: 0.8028\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.5902 - accuracy: 0.7934\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.5470 - accuracy: 0.8169\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.5367 - accuracy: 0.7934\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 23s 3s/step - loss: 0.6942 - accuracy: 0.7746\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 23s 3s/step - loss: 0.5044 - accuracy: 0.8263\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.5024 - accuracy: 0.8075\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 23s 3s/step - loss: 0.4693 - accuracy: 0.8357\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.4060 - accuracy: 0.8310\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5134 - accuracy: 0.8216\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.4762 - accuracy: 0.8404\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.5916 - accuracy: 0.7653\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 23s 3s/step - loss: 0.5062 - accuracy: 0.8075\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 24s 4s/step - loss: 0.4751 - accuracy: 0.8404\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.5053 - accuracy: 0.8498\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.3460 - accuracy: 0.8873\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.4333 - accuracy: 0.8545\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.3968 - accuracy: 0.8732\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.3446 - accuracy: 0.8685\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.3537 - accuracy: 0.8873\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.3665 - accuracy: 0.8920\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.3127 - accuracy: 0.8779\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.2710 - accuracy: 0.8920\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 23s 3s/step - loss: 0.3958 - accuracy: 0.8685\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.2718 - accuracy: 0.8873\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 23s 3s/step - loss: 0.4203 - accuracy: 0.8545\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.3234 - accuracy: 0.8967\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.4252 - accuracy: 0.8592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18d2fe66ca0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(valid_generator, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/217 - 37s - loss: 1.2193 - accuracy: 0.6959\n",
      "\n",
      "Test accuracy: 0.695852518081665\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1024)         2098176     global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1024)         0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1024)         1049600     dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1024)         0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1024)         1049600     dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 12)           12300       dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 27,797,388\n",
      "Trainable params: 4,209,676\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('IAM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('IAM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1024)         2098176     global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1024)         0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1024)         1049600     dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1024)         0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1024)         1049600     dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 12)           12300       dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 27,797,388\n",
      "Trainable params: 4,209,676\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy : 66.82027649769586\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(r\"E:\\ML\\IBM hackathon research-forensic\\data_subset\\IAM.h5\")\n",
    "filenames = test_generator.filenames\n",
    "nb_samples = len(test_generator)\n",
    "y_prob=[]\n",
    "y_act=[]\n",
    "test_generator.reset()\n",
    "for _ in range(nb_samples):\n",
    "    X_test,Y_test = test_generator.next()\n",
    "    y_prob.append(model.predict(X_test))\n",
    "    y_act.append(Y_test)\n",
    "\n",
    "predicted_class = [list(train_generator.class_indices.keys())[i.argmax()] for i in y_prob]\n",
    "actual_class = [list(train_generator.class_indices.keys())[i.argmax()] for i in y_act]\n",
    "\n",
    "out_df = pd.DataFrame(np.vstack([predicted_class,actual_class]).T,columns=['predicted_class','actual_class'])\n",
    "confusion_matrix = pd.crosstab(out_df['actual_class'],out_df['predicted_class'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "sns.heatmap(confusion_matrix,cmap='Blues', annot=True,fmt='d')\n",
    "plt.show()\n",
    "print('Test accuracy : {}'.format((np.diagonal(confusion_matrix).sum()/confusion_matrix.sum().sum()*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P06'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "img = keras.preprocessing.image.load_img(r'E:\\ML\\IBM hackathon research-forensic\\data_subset\\Authors\\a01\\a01-003u-s01-04.png')\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "class_names = ['A01', 'A02', 'A05', 'B06', 'C03', 'C06','G06','J06','M06','N06','P06','R06']\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "class_names[np.argmax(score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P06'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "img = keras.preprocessing.image.load_img(r'E:\\ML\\IBM hackathon research-forensic\\data_subset\\Authors-processed_data\\train\\b06\\b06-056-s00-00.png')\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "class_names = ['A01', 'A02', 'A05', 'B06', 'C03', 'C06','G06','J06','M06','N06','P06','R06']\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "class_names[np.argmax(score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a01\\\\a01-000u-s00-03.png',\n",
       " 'a01\\\\a01-003u-s01-00.png',\n",
       " 'a01\\\\a01-003u-s01-01.png',\n",
       " 'a01\\\\a01-003u-s01-03.png',\n",
       " 'a01\\\\a01-003u-s01-04.png',\n",
       " 'a01\\\\a01-007u-s00-01.png',\n",
       " 'a01\\\\a01-007u-s01-00.png',\n",
       " 'a01\\\\a01-011u-s00-02.png',\n",
       " 'a01\\\\a01-011u-s00-03.png',\n",
       " 'a01\\\\a01-011u-s01-01.png',\n",
       " 'a01\\\\a01-014u-s00-00.png',\n",
       " 'a01\\\\a01-014u-s01-00.png',\n",
       " 'a01\\\\a01-014u-s02-00.png',\n",
       " 'a01\\\\a01-014u-s03-00.png',\n",
       " 'a01\\\\a01-014u-s04-00.png',\n",
       " 'a01\\\\a01-020u-s00-01.png',\n",
       " 'a01\\\\a01-020u-s02-01.png',\n",
       " 'a01\\\\a01-026u-s00-01.png',\n",
       " 'a01\\\\a01-026u-s02-00.png',\n",
       " 'a01\\\\a01-026u-s02-02.png',\n",
       " 'a01\\\\a01-030u-s00-00.png',\n",
       " 'a01\\\\a01-043u-s00-01.png',\n",
       " 'a01\\\\a01-043u-s01-02.png',\n",
       " 'a01\\\\a01-043u-s04-00.png',\n",
       " 'a01\\\\a01-043u-s04-03.png',\n",
       " 'a01\\\\a01-049u-s00-00.png',\n",
       " 'a02\\\\a02-017-s00-00.png',\n",
       " 'a02\\\\a02-017-s01-02.png',\n",
       " 'a02\\\\a02-017-s01-03.png',\n",
       " 'a02\\\\a02-020-s00-00.png',\n",
       " 'a02\\\\a02-024-s01-01.png',\n",
       " 'a02\\\\a02-024-s01-02.png',\n",
       " 'a02\\\\a02-027-s00-00.png',\n",
       " 'a02\\\\a02-027-s00-02.png',\n",
       " 'a02\\\\a02-027-s03-01.png',\n",
       " 'a02\\\\a02-037-s00-01.png',\n",
       " 'a02\\\\a02-037-s01-00.png',\n",
       " 'a02\\\\a02-037-s02-01.png',\n",
       " 'a05\\\\a05-000-s00-03.png',\n",
       " 'a05\\\\a05-013-s00-01.png',\n",
       " 'a05\\\\a05-013-s01-00.png',\n",
       " 'a05\\\\a05-013-s01-01.png',\n",
       " 'a05\\\\a05-013-s01-03.png',\n",
       " 'a05\\\\a05-013-s02-00.png',\n",
       " 'a05\\\\a05-013-s02-01.png',\n",
       " 'a05\\\\a05-013-s02-04.png',\n",
       " 'a05\\\\a05-017-s03-02.png',\n",
       " 'a05\\\\a05-025-s00-01.png',\n",
       " 'a05\\\\a05-025-s01-00.png',\n",
       " 'a05\\\\a05-025-s01-02.png',\n",
       " 'a05\\\\a05-025-s02-01.png',\n",
       " 'a05\\\\a05-029-s01-01.png',\n",
       " 'a05\\\\a05-039-s00-00.png',\n",
       " 'a05\\\\a05-039-s01-01.png',\n",
       " 'a05\\\\a05-039-s02-02.png',\n",
       " 'a05\\\\a05-039-s03-01.png',\n",
       " 'a05\\\\a05-044-s00-00.png',\n",
       " 'a05\\\\a05-048-s00-00.png',\n",
       " 'a05\\\\a05-048-s02-00.png',\n",
       " 'a05\\\\a05-048-s03-03.png',\n",
       " 'a05\\\\a05-053-s02-01.png',\n",
       " 'b06\\\\b06-000-s00-01.png',\n",
       " 'b06\\\\b06-000-s02-01.png',\n",
       " 'b06\\\\b06-000-s02-02.png',\n",
       " 'b06\\\\b06-008-s00-00.png',\n",
       " 'b06\\\\b06-012-s01-00.png',\n",
       " 'b06\\\\b06-012-s01-01.png',\n",
       " 'b06\\\\b06-019-s00-00.png',\n",
       " 'b06\\\\b06-019-s00-02.png',\n",
       " 'b06\\\\b06-019-s02-01.png',\n",
       " 'b06\\\\b06-023-s00-01.png',\n",
       " 'b06\\\\b06-023-s00-02.png',\n",
       " 'b06\\\\b06-032-s01-00.png',\n",
       " 'b06\\\\b06-032-s02-02.png',\n",
       " 'b06\\\\b06-032-s02-03.png',\n",
       " 'c03\\\\c03-003f-s02-00.png',\n",
       " 'c03\\\\c03-007a-s01-03.png',\n",
       " 'c03\\\\c03-007a-s01-04.png',\n",
       " 'c03\\\\c03-007b-s00-00.png',\n",
       " 'c03\\\\c03-007b-s00-01.png',\n",
       " 'c03\\\\c03-007c-s00-00.png',\n",
       " 'c03\\\\c03-007c-s00-01.png',\n",
       " 'c03\\\\c03-007d-s01-02.png',\n",
       " 'c03\\\\c03-007e-s00-02.png',\n",
       " 'c03\\\\c03-007e-s01-03.png',\n",
       " 'c03\\\\c03-007e-s01-06.png',\n",
       " 'c03\\\\c03-007f-s00-01.png',\n",
       " 'c03\\\\c03-007f-s01-02.png',\n",
       " 'c03\\\\c03-007f-s01-03.png',\n",
       " 'c03\\\\c03-016a-s00-01.png',\n",
       " 'c03\\\\c03-016a-s02-04.png',\n",
       " 'c03\\\\c03-016b-s02-01.png',\n",
       " 'c03\\\\c03-016c-s00-01.png',\n",
       " 'c03\\\\c03-016c-s02-00.png',\n",
       " 'c03\\\\c03-016c-s02-02.png',\n",
       " 'c03\\\\c03-016d-s03-01.png',\n",
       " 'c03\\\\c03-016e-s01-00.png',\n",
       " 'c03\\\\c03-016e-s03-02.png',\n",
       " 'c03\\\\c03-021a-s00-00.png',\n",
       " 'c03\\\\c03-021a-s00-01.png',\n",
       " 'c03\\\\c03-021a-s01-01.png',\n",
       " 'c06\\\\c06-000-s01-00.png',\n",
       " 'c06\\\\c06-000-s03-01.png',\n",
       " 'c06\\\\c06-000-s03-02.png',\n",
       " 'c06\\\\c06-000-s03-03.png',\n",
       " 'c06\\\\c06-005-s04-04.png',\n",
       " 'c06\\\\c06-011-s00-00.png',\n",
       " 'c06\\\\c06-011-s00-03.png',\n",
       " 'c06\\\\c06-011-s00-05.png',\n",
       " 'c06\\\\c06-020-s01-00.png',\n",
       " 'c06\\\\c06-020-s02-02.png',\n",
       " 'c06\\\\c06-020-s03-00.png',\n",
       " 'c06\\\\c06-027-s01-01.png',\n",
       " 'c06\\\\c06-031-s00-00.png',\n",
       " 'c06\\\\c06-031-s00-01.png',\n",
       " 'g06\\\\g06-018e-s02-02.png',\n",
       " 'g06\\\\g06-018g-s01-00.png',\n",
       " 'g06\\\\g06-018g-s01-01.png',\n",
       " 'g06\\\\g06-018g-s02-00.png',\n",
       " 'g06\\\\g06-018g-s02-01.png',\n",
       " 'g06\\\\g06-018h-s02-00.png',\n",
       " 'g06\\\\g06-018h-s02-01.png',\n",
       " 'g06\\\\g06-018j-s00-02.png',\n",
       " 'g06\\\\g06-018j-s02-03.png',\n",
       " 'g06\\\\g06-018k-s00-00.png',\n",
       " 'g06\\\\g06-018k-s01-00.png',\n",
       " 'g06\\\\g06-018k-s02-00.png',\n",
       " 'g06\\\\g06-018k-s02-02.png',\n",
       " 'g06\\\\g06-018l-s01-00.png',\n",
       " 'g06\\\\g06-018l-s01-01.png',\n",
       " 'g06\\\\g06-018m-s00-00.png',\n",
       " 'g06\\\\g06-018m-s02-02.png',\n",
       " 'g06\\\\g06-018n-s01-04.png',\n",
       " 'g06\\\\g06-018o-s01-00.png',\n",
       " 'g06\\\\g06-018o-s02-00.png',\n",
       " 'g06\\\\g06-018p-s02-03.png',\n",
       " 'g06\\\\g06-018r-s00-00.png',\n",
       " 'g06\\\\g06-018r-s01-02.png',\n",
       " 'g06\\\\g06-026a-s00-00.png',\n",
       " 'j06\\\\j06-000-s01-00.png',\n",
       " 'j06\\\\j06-000-s02-01.png',\n",
       " 'j06\\\\j06-000-s02-02.png',\n",
       " 'j06\\\\j06-000-s02-03.png',\n",
       " 'j06\\\\j06-005-s01-02.png',\n",
       " 'j06\\\\j06-005-s01-03.png',\n",
       " 'j06\\\\j06-008-s00-01.png',\n",
       " 'j06\\\\j06-008-s00-02.png',\n",
       " 'j06\\\\j06-008-s01-00.png',\n",
       " 'j06\\\\j06-008-s01-01.png',\n",
       " 'j06\\\\j06-008-s01-02.png',\n",
       " 'm06\\\\m06-019-s00-00.png',\n",
       " 'm06\\\\m06-019-s04-00.png',\n",
       " 'm06\\\\m06-019-s04-01.png',\n",
       " 'm06\\\\m06-019-s05-00.png',\n",
       " 'm06\\\\m06-031-s05-00.png',\n",
       " 'm06\\\\m06-031-s06-00.png',\n",
       " 'm06\\\\m06-031-s07-00.png',\n",
       " 'm06\\\\m06-031-s08-00.png',\n",
       " 'm06\\\\m06-031-s09-00.png',\n",
       " 'm06\\\\m06-042-s02-01.png',\n",
       " 'm06\\\\m06-056-s01-00.png',\n",
       " 'n06\\\\n06-074-s01-00.png',\n",
       " 'n06\\\\n06-074-s02-02.png',\n",
       " 'n06\\\\n06-074-s03-00.png',\n",
       " 'n06\\\\n06-074-s04-00.png',\n",
       " 'n06\\\\n06-082-s06-00.png',\n",
       " 'n06\\\\n06-082-s06-01.png',\n",
       " 'n06\\\\n06-082-s08-01.png',\n",
       " 'n06\\\\n06-092-s00-00.png',\n",
       " 'n06\\\\n06-092-s04-00.png',\n",
       " 'n06\\\\n06-092-s06-00.png',\n",
       " 'n06\\\\n06-092-s06-01.png',\n",
       " 'n06\\\\n06-100-s04-01.png',\n",
       " 'n06\\\\n06-100-s08-00.png',\n",
       " 'n06\\\\n06-100-s09-00.png',\n",
       " 'n06\\\\n06-100-s09-01.png',\n",
       " 'n06\\\\n06-111-s00-00.png',\n",
       " 'n06\\\\n06-111-s02-00.png',\n",
       " 'n06\\\\n06-111-s06-00.png',\n",
       " 'n06\\\\n06-111-s06-01.png',\n",
       " 'p06\\\\p06-030-s00-01.png',\n",
       " 'p06\\\\p06-030-s03-01.png',\n",
       " 'p06\\\\p06-030-s04-00.png',\n",
       " 'p06\\\\p06-030-s05-00.png',\n",
       " 'p06\\\\p06-042-s00-02.png',\n",
       " 'p06\\\\p06-042-s01-01.png',\n",
       " 'p06\\\\p06-042-s02-00.png',\n",
       " 'p06\\\\p06-042-s03-00.png',\n",
       " 'p06\\\\p06-042-s03-01.png',\n",
       " 'p06\\\\p06-042-s03-02.png',\n",
       " 'p06\\\\p06-047-s01-03.png',\n",
       " 'p06\\\\p06-047-s02-04.png',\n",
       " 'r06\\\\r06-000-s01-00.png',\n",
       " 'r06\\\\r06-003-s02-00.png',\n",
       " 'r06\\\\r06-003-s02-01.png',\n",
       " 'r06\\\\r06-003-s02-03.png',\n",
       " 'r06\\\\r06-003-s02-04.png',\n",
       " 'r06\\\\r06-007-s02-01.png',\n",
       " 'r06\\\\r06-007-s02-02.png',\n",
       " 'r06\\\\r06-011-s04-00.png',\n",
       " 'r06\\\\r06-018-s00-03.png',\n",
       " 'r06\\\\r06-018-s02-01.png',\n",
       " 'r06\\\\r06-022-s00-02.png',\n",
       " 'r06\\\\r06-022-s02-00.png',\n",
       " 'r06\\\\r06-022-s02-02.png',\n",
       " 'r06\\\\r06-022-s02-03.png',\n",
       " 'r06\\\\r06-027-s01-00.png',\n",
       " 'r06\\\\r06-027-s05-00.png',\n",
       " 'r06\\\\r06-035-s02-01.png',\n",
       " 'r06\\\\r06-041-s00-02.png',\n",
       " 'r06\\\\r06-041-s00-04.png',\n",
       " 'r06\\\\r06-041-s01-00.png',\n",
       " 'r06\\\\r06-044-s03-03.png',\n",
       " 'r06\\\\r06-049-s00-02.png',\n",
       " 'r06\\\\r06-049-s02-00.png',\n",
       " 'r06\\\\r06-049-s02-03.png',\n",
       " 'r06\\\\r06-049-s02-04.png']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
       "array([0.07563975, 0.0757563 , 0.07552669, 0.07720173, 0.07582581,\n",
       "       0.0756048 , 0.07828624, 0.07591554, 0.07560074, 0.07689998,\n",
       "       0.11675594, 0.12098652], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
